import{_ as i,c as a,o as n,ag as l}from"./chunks/framework.DPDPlp3K.js";const c=JSON.parse('{"title":"感知与解析","description":"","frontmatter":{},"headers":[],"relativePath":"ai-agent/abilities/perception.md","filePath":"ai-agent/abilities/perception.md","lastUpdated":1747212070000}'),e={name:"ai-agent/abilities/perception.md"};function p(t,s,h,k,r,d){return n(),a("div",null,s[0]||(s[0]=[l(`<h1 id="感知与解析" tabindex="-1">感知与解析 <a class="header-anchor" href="#感知与解析" aria-label="Permalink to &quot;感知与解析&quot;">​</a></h1><h2 id="_1-能力简介" tabindex="-1">1. 能力简介 <a class="header-anchor" href="#_1-能力简介" aria-label="Permalink to &quot;1. 能力简介&quot;">​</a></h2><p>感知与解析（Perception）是 AI Agent 获取和理解外部环境信息的基础能力。通过自然语言处理（NLP）、计算机视觉（CV）、语音识别（ASR）、光学字符识别（OCR）等技术，智能体能够感知文本、语音、图像、视频等多模态输入。</p><h2 id="_2-主要原理与关键技术" tabindex="-1">2. 主要原理与关键技术 <a class="header-anchor" href="#_2-主要原理与关键技术" aria-label="Permalink to &quot;2. 主要原理与关键技术&quot;">​</a></h2><ul><li><strong>自然语言处理（NLP）</strong>：文本分词、意图识别、实体抽取、情感分析等</li><li><strong>计算机视觉（CV）</strong>：图像分类、目标检测、场景理解等</li><li><strong>语音识别（ASR）</strong>：语音转文本、关键词提取</li><li><strong>光学字符识别（OCR）</strong>：图片中的文字识别与解析</li><li><strong>多模态融合</strong>：跨模态信息整合与理解</li></ul><h2 id="_3-jsdoc-代码示例" tabindex="-1">3. JSDoc 代码示例 <a class="header-anchor" href="#_3-jsdoc-代码示例" aria-label="Permalink to &quot;3. JSDoc 代码示例&quot;">​</a></h2><div class="language-js vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">js</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">/**</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> * 文本意图解析示例</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> * </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">@param</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> {string}</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> text</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> - 用户输入文本</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> * </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">@param</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> {object}</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nlpModel</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> - NLP 模型接口</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> * </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">@returns</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> {Promise&lt;object&gt;}</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> 解析结果</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> */</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">async</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> function</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> parseIntent</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">text</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">nlpModel</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) {</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">  return</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> await</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nlpModel.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">parse</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(text);</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">/**</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> * 图像识别示例</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> * </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">@param</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> {string}</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> imagePath</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> - 图像文件路径</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> * </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">@param</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> {object}</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> cvModel</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> - 计算机视觉模型接口</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> * </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">@returns</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> {Promise&lt;object&gt;}</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> 识别结果</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> */</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">async</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> function</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> recognizeImage</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">imagePath</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">cvModel</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) {</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">  return</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> await</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> cvModel.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">classify</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(imagePath);</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br></div></div><h2 id="_4-实践要点与扩展建议" tabindex="-1">4. 实践要点与扩展建议 <a class="header-anchor" href="#_4-实践要点与扩展建议" aria-label="Permalink to &quot;4. 实践要点与扩展建议&quot;">​</a></h2><ul><li>选择适合场景的感知模型（如通用大模型或专用小模型）</li><li>支持多模态输入，提升智能体适应性</li><li>加强数据预处理与异常检测，提升感知准确率</li><li>可结合外部 API（如 OCR、ASR 云服务）扩展能力</li></ul><hr><p>感知与解析是 AI Agent 的第一步，决定了后续决策与行动的基础质量。</p>`,11)]))}const o=i(e,[["render",p]]);export{c as __pageData,o as default};
